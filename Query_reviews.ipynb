{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f8e313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emilh/anaconda3/envs/ou/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os, sys, contextlib\n",
    "from txtai.embeddings import Embeddings\n",
    "from txtai.pipeline import Extractor\n",
    "import re\n",
    "import pandas as pd\n",
    "from langchain import FAISS\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc0717-95e3-4ed9-9fb0-817da311b6de",
   "metadata": {},
   "source": [
    "# Guide: Query reviews\n",
    "To query reviews using the respective chunking strategies and embedding models, follow these steps:\n",
    "- Ensure that the embeddings are generated and stored in the data/Embedding/ folder.\n",
    "- A pre-generated embedding for sentence chunking + all-MiniLM-L6-v2 based on 5k reviews is provided within this repository. Due to github size limitations, embeddings for all chunking methods, embedding models and the number of reviews (20k) used in the case study are not included.\n",
    "- To generate other embeddings use the files provided in this repository opinion_unit_CREATE_EMBED_STORE.ipynb and sentence_passage_chunking_CREATE_EMBED_STORE.ipynb.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ad794",
   "metadata": {},
   "source": [
    "### Read the raw review files\n",
    "##### (In order to link the Doc_Id for each retrieved chunk --> full review text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47fcc34c-5ada-4ad8-8b3a-f424a0b76051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"YELP\"\n",
    "data_path = 'data/YELP/yelp_subset.pkl'\n",
    "# Load a DataFrame of a subset of 20k YELP restaurant reviews from a pickle file\n",
    "df_reviews = pd.read_pickle(data_path)\n",
    "# Reset the index and rename the index column to \"Doc Id\"\n",
    "df_reviews.reset_index(inplace=True)\n",
    "df_reviews.rename(columns={'index': 'Doc Id'}, inplace=True)\n",
    "# Rename the column from 'text' to 'Doc Text'\n",
    "df_reviews.rename(columns={'text': 'Doc Text'}, inplace=True)\n",
    "columns_to_keep = ['Doc Id', 'review_id',\"business_id\",\"stars\",\"Doc Text\"]\n",
    "# Keep only the columns in the list\n",
    "df_reviews = df_reviews[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea91eb",
   "metadata": {},
   "source": [
    "#### Chunking stragies \n",
    "1. \"sentence_chunking\"\n",
    "2. \"pasage_chunking\"\n",
    "3. \"opinion_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd3da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_246185/810249709.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=embed_model)\n"
     ]
    }
   ],
   "source": [
    "chunking_strategy=\"sentence_chunking\" \n",
    "dataset=\"YELP\"\n",
    "embed_model= \"all-MiniLM-L6-v2\"#, \"all-mpnet-base-v2\"\n",
    "saved_to=\"data/Embeddings/\" + dataset + \"_\" + chunking_strategy\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "788b60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_faiss = FAISS.load_local(saved_to, embedding_function, index_name=\"index\", allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016538a0",
   "metadata": {},
   "source": [
    "### Functions for printing the search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chunks(res):\n",
    "    \"\"\"\n",
    "    Just print the chunk and the review Id\n",
    "    \"\"\"\n",
    "    counter=1\n",
    "    for r in res:\n",
    "        doc_id=r[0].metadata[\"review_id\"]\n",
    "        review_ID= df_reviews[df_reviews[\"Doc Id\"]==doc_id][\"review_id\"].values[0]\n",
    "        print(\"#\"+str(counter), \"Doc ID:\", r[0].metadata[\"review_id\"])\n",
    "        print(\"Chunk:\",r[0].page_content)\n",
    "        print(\"\\n\")\n",
    "        counter+=1\n",
    "    return \n",
    "\n",
    "def print_chunks_and_reviews(res):\n",
    "    \"\"\"\n",
    "    Print chunk, review Id + full review text. \n",
    "    \n",
    "    Review text is retrieved through the df_reviews dataframe wthich links doc ids to review texts\n",
    "    \"\"\"\n",
    "    counter=1\n",
    "    for r in res:\n",
    "        print(\"#\"+str(counter),\"Doc ID:\", r[0].metadata[\"review_id\"])\n",
    "        print(\"Chunk:\",r[0].page_content)\n",
    "        doc_id=r[0].metadata[\"review_id\"]\n",
    "        review_ID= df_reviews[df_reviews[\"Doc Id\"]==doc_id][\"review_id\"].values[0]\n",
    "        review_text= df_reviews[df_reviews[\"Doc Id\"]==doc_id][\"Doc Text\"].values[0]\n",
    "        print(\"Full review:\\n\"+ review_text)\n",
    "        print(\"\\n\")\n",
    "        counter+=1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63edc56-6619-4871-b48c-bf20b4871be3",
   "metadata": {},
   "source": [
    "## Query the reviews!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63d3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Doc ID: 172353\n",
      "Chunk: The pasta was great!\n",
      "\n",
      "\n",
      "#2 Doc ID: 170042\n",
      "Chunk: The pasta was by far my favorite main dish.\n",
      "\n",
      "\n",
      "#3 Doc ID: 108966\n",
      "Chunk: Not the best pasta I've ever had but it was quick and delicious.\n",
      "\n",
      "\n",
      "#4 Doc ID: 110056\n",
      "Chunk: The pasta is delicious.\n",
      "\n",
      "\n",
      "#5 Doc ID: 118311\n",
      "Chunk: The pasta is good.\n",
      "\n",
      "\n",
      "#6 Doc ID: 74279\n",
      "Chunk: All the pastas are excellent too.\n",
      "\n",
      "\n",
      "#7 Doc ID: 131\n",
      "Chunk: The pasta was delicious, the calzones were phenomenal, and the pizza was so good.\n",
      "\n",
      "\n",
      "#8 Doc ID: 152950\n",
      "Chunk: Great pasta and environment.\n",
      "\n",
      "\n",
      "#9 Doc ID: 98589\n",
      "Chunk: The pasta... and more pasta!\n",
      "\n",
      "\n",
      "#10 Doc ID: 176198\n",
      "Chunk: The food was incredible!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query to retrieve documents\n",
    "query=\"The pasta was superb!\"\n",
    "# Set the number of reviews to return \n",
    "n_reviews=10\n",
    "res=loaded_faiss.similarity_search_with_score(query,n_reviews)\n",
    "# Select whether to print only the retrieved chunk or also the full review text.\n",
    "print_chunks(res)\n",
    "#print_chunks_and_reviews(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bb8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7f232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
